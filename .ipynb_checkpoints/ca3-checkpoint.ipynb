{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"font-size: 35px; text-align: center;\">AI CA3</h1>\n",
    "<h1 style = \"font-size: 35px; text-align: center;\">Data processing and bayesian networks</h1>\n",
    "<h1 style = \"font-size: 32px; text-align: center; color: #666\">Taha Shabani 810196491</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style = \"text-align: center\">Prelude</h1>\n",
    "<br>\n",
    "<h2>Definition of project:</h2>\n",
    "<p style = \"font-size: 14px\">Text classification is useful in lots of aspects, for instance: spam email recognition, automatic book classification and ...\n",
    "<br>    \n",
    "The goal of this project is to classify texts based on <mark>short_descriptions</mark> and headlines. We already have three main categories: <b>travel, business, and style&beauty </b> and data stored at <mark>data.csv</mark>.\n",
    "<br>\n",
    "First of all we train system with 80 percent of total data: (training data) with a strategy called <b>bag of words </b>, then for evaulation we use rest of the the data. And measure accuracy, recall, and precision for every category.\n",
    "<br>\n",
    "Ultimately we label data in <mark>test.csv</mark> based on the bag of words we've gained previously. \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<h1 style= \"text-align: center\">Prerequisites </h1>\n",
    "<br>\n",
    "<h3> 1. Preprocessing data: </h3>\n",
    "<p><mark>PreprocessData()</mark>: Every context in training data should be preprocessed in order to extract main words and to calculate probability of words per categories. preprocessing steps are shown below:</p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>lowerAllCharacters()</mark>: This function lower capital letters as a simplification.</p>\n",
    "<p style=\"text-indent :2em;\">2. <mark>removeStopWordsAndPunctuations()</mark>: This function uses <b>nltk library</b> and tokenizer to remove <b>stopWords and punctuations</b>.</p>\n",
    "<p style=\"text-indent :2em;\">3. <mark>lemmatizeWords()</mark>: nltk provide a tool to lemmatize words (revert to original form) and we used this function to do so.</p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<h3> 2. What is bag or words model? </h3>\n",
    "<p>Bag of words is a model which is insensitive to word orders. it uses bayesian networks and naive bayes to calculate probabilites. In our model we have 4 types of probabilites: </p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>Posterier: p(c|x)</mark>: If we have the <b>x</b> as a word in our text, what is the probability of <b>c</b> category for this text.</p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>Prior: p(c)</mark>: the probability of <b>c</b> as category (calculated based on training data). </p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>Likelihood: p(x|c)</mark>: If we know that <b>c</b> is category of current text, what is the probability that this text contains word <b>x</b>.</p>\n",
    "<p style=\"text-indent :2em;\">1. <mark>Evidence: p(x)</mark>: the probability of exitance of <b>x</b> as a word in text. We devide the number of current word to total words to calculate p(x) for every x.</p>\n",
    "<p><b>NOTE 1</b>: At the end we use <b>p(c|X = {x1,x2,x3,...}) = p(x1|c)*p(x2|c)* ..... * p(c)</b> to evaluate.\n",
    "    \n",
    "\n",
    "<br>\n",
    "<h3> 3. Oversampling: </h3>\n",
    "<p><b>Oversampling</b> in data analysis is techniques used to adjust the class distribution of a data set (i.e. the ratio between the different classes/categories represented). These terms are used both in statistical sampling, survey design methodology and in machine learning.</p>\n",
    "<p>In order to perform oversampling we replicate data from minor classes to reach the amount of major class size. </p>\n",
    "<p><b>Why we use oversampling</b>: As said above and as it's clear, this is a technique to remove imbalances and to gain high precision. without oversampling we might have good accuracy but precision for minor classes would be bad.</p>\n",
    "<p>Oversampling is implemented in <mark>getDatas()</mark> in Classifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from itertools import zip_longest\n",
    "\n",
    "dataFile = \"data.csv\"\n",
    "testFile = \"test.csv\"\n",
    "\n",
    "\n",
    "def removeStopWordsAndPunctuations(context) :\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    context = tokenizer.tokenize(context)\n",
    "    \n",
    "    filtered_sentence = [] \n",
    "    \n",
    "    for w in context: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def lowerAllCharacters(context) :\n",
    "    context = context.lower()\n",
    "    return context\n",
    "\n",
    "def lemmatizeWords(wordList) : \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(wordList)):\n",
    "        wordList[i] = lemmatizer.lemmatize(wordList[i])\n",
    "    return wordList\n",
    "\n",
    "def preprocessData(context) : \n",
    "    context = lowerAllCharacters(context)   \n",
    "    wordList = removeStopWordsAndPunctuations(context)\n",
    "    wordList = lemmatizeWords(wordList)\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h1 style= \"text-align: center\">Process steps </h1>\n",
    "<h2>Initialization:</h2>\n",
    "<p><mark>__init__()</mark>:</p>\n",
    "<p style=\"text-indent :2em;\"> 1. <mark>getDatas()</mark>: <b>Reading and spliting</b> data into training and evaluating parts per every category.<b>80 precent of every category is labeled as training data and the rest is evaluation data. But why? Because we should make a balance for categories both in training data and evaluation data to reach an acceptable accuracy. and if we don't so, some categories might not be trained well.</b>  then performing <b>oversampling</b> to remove imbalance.</p>\n",
    "<p style=\"text-indent :2em;\"> 2. <mark>calculatePWords()</mark>: Computing probability of every word for every category. the probability of word \"x\" in category \"c\" is calculated like this:<b>(number of \"x\" in total contexts of \"c\" category) / (number of total words in \"c\" category)</b>. This function uses <mark>preprocessData()</mark> inside.</p>\n",
    "<br>\n",
    "\n",
    "<h2>Evaluation: Classify phase 1:</h2>\n",
    "<p><mark>classify2()</mark>: This function only classifies evaluate data for two major class: <b>TRAVEL and BUSINESS</b>.\n",
    "</p>\n",
    "<p style=\"text-indent :2em;\"> 1. <mark>classify2EvaluateDatas()</mark>: This function reads every context from a evaluate data of a certain category, extracts its words (from columns: <b>short_description and headlines</b>) and save these extracted words, then calculate probability based on <b>NOTE 1</b> as mentioned above. but there is a problem: in order to calculate total probability, we used logarithm of probability because, during calculation, the result would be very little and python would recognize as exact zero, so we save its logarithm instead. Then we compare the results for different categories and determine true category.</p>\n",
    "<p style=\"text-indent :2em;\"> 2. <mark>Rest of the function</mark>: Is to form datafram to show results based on: recall, precision, and accuracy.</p>\n",
    "\n",
    "<h2>Evaluation: Classify phase 2:</h2>\n",
    "<p><mark>classify3()</mark>: Same as phase 1 but with more categories: <b>TRAVEL and BUSINESS and STYLE&BEAUTY</b>.\n",
    "</p>\n",
    "<p style=\"text-indent :2em;\"> 1. <mark>classify3EvaluateDatas()</mark>: Similar to classify2EvaluateDatas() but for 3 categories, plus, it uses extracted words from classify2EvaluateDatas().</p>\n",
    "<p style=\"text-indent :2em;\"> 2. <mark>Rest of the function</mark>: Is to form datafram to show results based on: recall, precision, and accuracy.</p>\n",
    "\n",
    "<h2>Evaluating test file:</h2>\n",
    "<p><mark>EvaluateTestFile()</mark>: reads data from testFile and perform classification based on phase2 way. Then save result in <b>output.csv</b> with 2 columns: <b>indexes and categories detected</b>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier :\n",
    "    def __init__(self, dataFile) :\n",
    "        [self.travelTrainData, self.travelEvaluateData, self.businessTrainData, self.businessEvaluateData, self.styleTrainData, self.styleEvaluateData] = self.getDatas(dataFile)\n",
    "        \n",
    "        self.pt = (len(self.travelTrainData) / (len(self.travelTrainData) + len(self.businessTrainData) + len(self.styleTrainData)))\n",
    "        self.pb = (len(self.businessTrainData) / (len(self.travelTrainData) + len(self.businessTrainData) + len(self.styleTrainData)))\n",
    "        self.ps = (len(self.styleTrainData) / (len(self.travelTrainData) + len(self.businessTrainData) + len(self.styleTrainData)))\n",
    "        print(\"data.csv reading done.\")\n",
    "        self.ptWords = self.calculatePWords(self.travelTrainData)\n",
    "        print(\"words' probability of travels done.\")\n",
    "        self.pbWords = self.calculatePWords(self.businessTrainData)\n",
    "        print(\"words' probability of buisiness done.\")\n",
    "        self.psWords = self.calculatePWords(self.styleTrainData)\n",
    "        print(\"words' probability of style & beauty done.\")\n",
    "        \n",
    "    \n",
    "    def getDatas(self, dataFile) : \n",
    "        col_list = [\"index\", \"category\", \"headline\", \"short_description\"]\n",
    "        df = pd.read_csv(dataFile, usecols=col_list)\n",
    "        travelData = []\n",
    "        businessData = []\n",
    "        styleData = []\n",
    "        for index, dfRow in df.iterrows() : \n",
    "            if dfRow[1] == \"TRAVEL\" : \n",
    "                travelData.append(dfRow)\n",
    "            elif dfRow[1] == \"BUSINESS\" : \n",
    "                businessData.append(dfRow)\n",
    "            elif dfRow[1] == \"STYLE & BEAUTY\" : \n",
    "                styleData.append(dfRow)\n",
    "        \n",
    "        travelSize = len(travelData)\n",
    "        businessSize = len(businessData)\n",
    "        styleSize = len(styleData)\n",
    "        \n",
    "        \n",
    "        maxSize = max(travelSize, businessSize, styleSize)\n",
    "        \n",
    "        if (travelSize < maxSize) : \n",
    "            l1 = list(range(travelSize))\n",
    "            travelIndices = np.random.choice(l1, maxSize)\n",
    "            travelData2 = []\n",
    "            for i in range(maxSize) : \n",
    "                travelData2.append(travelData[travelIndices[i]])\n",
    "            travelData = travelData2\n",
    "        \n",
    "        if (businessSize < maxSize) : \n",
    "            l1 = list(range(businessSize))\n",
    "            businessIndices = np.random.choice(l1, maxSize)\n",
    "            businessData2 = []\n",
    "            for i in range(maxSize) : \n",
    "                businessData2.append(businessData[businessIndices[i]])\n",
    "            businessData = businessData2\n",
    "                \n",
    "        if (styleSize < maxSize) : \n",
    "            l1 = list(range(styleSize))\n",
    "            styleIndices = np.random.choice(l1, maxSize)\n",
    "            styleData2 = []\n",
    "            for i in range(maxSize) : \n",
    "                styleData2.append(styleData[styleIndices[i]])\n",
    "            styleData = styleData2\n",
    "        \n",
    "        travelSize = len(travelData)\n",
    "        businessSize = len(businessData)\n",
    "        styleSize = len(styleData)\n",
    "        \n",
    "        travelTrainData = []\n",
    "        businessTrainData = []\n",
    "        styleTrainData = []\n",
    "        travelEvaluateData = []\n",
    "        buisinessEvaluateData = []\n",
    "        styleEvaluateData = []\n",
    "        \n",
    "        for i in range(travelSize) :\n",
    "            if (i <= (int)(travelSize * 0.8)) :\n",
    "                travelTrainData.append(travelData[i])\n",
    "            else:\n",
    "                travelEvaluateData.append(travelData[i])\n",
    "        for i in range(businessSize) :\n",
    "            if (i <= (int)(businessSize * 0.8)) :\n",
    "                businessTrainData.append(businessData[i])\n",
    "            else:\n",
    "                buisinessEvaluateData.append(businessData[i])\n",
    "        for i in range(styleSize) :\n",
    "            if (i <= (int)(styleSize * 0.8)) :\n",
    "                styleTrainData.append(styleData[i])\n",
    "            else:\n",
    "                styleEvaluateData.append(styleData[i])\n",
    "                \n",
    "        return [travelTrainData, travelEvaluateData, businessTrainData, buisinessEvaluateData, styleTrainData, styleEvaluateData]\n",
    "    \n",
    "    def getProcessedWords(self, dataSet) :\n",
    "        words = []\n",
    "        #row[2] -> headlines\n",
    "        #row[3] -> short_description\n",
    "        i = 0\n",
    "        for row in dataSet :  \n",
    "            i += 1 \n",
    "            headWordList = []\n",
    "            descWordList = []\n",
    "            if (not (isinstance(row[2], float) and math.isnan(row[2]))) : \n",
    "                headWordList = preprocessData(row[2])\n",
    "            if (not (isinstance(row[3], float) and math.isnan(row[3]))) : \n",
    "                descWordList = preprocessData(row[3])\n",
    "            \n",
    "            currentWords = headWordList + descWordList\n",
    "            words = words + currentWords\n",
    "        return words\n",
    "\n",
    "    def calculatePWords(self, dataSet) : \n",
    "        words = self.getProcessedWords(dataSet)\n",
    "        wordsSize = len(words)\n",
    "        wordDic = {}\n",
    "        for word in words :\n",
    "            if (word not in wordDic) :\n",
    "                wordDic[word] = 1/wordsSize\n",
    "            else: \n",
    "                wordDic[word] += 1/wordsSize\n",
    "        for word in wordDic:\n",
    "            wordDic[word] = math.log(wordDic[word], 10)\n",
    "        return wordDic \n",
    "    \n",
    "    def evaluateTravelP(self, wordList) :\n",
    "        pLog = 0\n",
    "        for word in wordList : \n",
    "            if (word in self.ptWords) : \n",
    "                pLog += self.ptWords[word]\n",
    "            else:\n",
    "                pLog += -6\n",
    "        return pLog\n",
    "    \n",
    "    def evaluateBusinessP(self, wordList) :\n",
    "        pLog = 0\n",
    "        for word in wordList : \n",
    "            if (word in self.pbWords) : \n",
    "                pLog += self.pbWords[word]\n",
    "            else:\n",
    "                pLog += -6\n",
    "        return pLog\n",
    "    \n",
    "    def evaluateStyleP(self, wordList) :\n",
    "        pLog = 0\n",
    "        for word in wordList : \n",
    "            if (word in self.psWords) : \n",
    "                pLog += self.psWords[word]\n",
    "            else:\n",
    "                pLog += -6\n",
    "        return pLog\n",
    "     \n",
    "    def classify2EvaluateDatas(self, data, dataType) :\n",
    "        i = 0\n",
    "        travelCount = 0\n",
    "        businessCount = 0\n",
    "        for row in data:\n",
    "            headWordList = []\n",
    "            descWordList = []\n",
    "            \n",
    "            if (type(row[2]) == list) :\n",
    "                headWordList = row[2]\n",
    "            elif (not (isinstance(row[2], float) and math.isnan(row[2]))) : \n",
    "                headWordList = preprocessData(row[2])\n",
    "            \n",
    "            if (type(row[3]) == list) :\n",
    "                descWordList = row[3]\n",
    "            elif (not (isinstance(row[3], float) and math.isnan(row[3]))) : \n",
    "                descWordList = preprocessData(row[3])\n",
    "            \n",
    "            currentWords = headWordList + descWordList\n",
    "            data[i][2] = currentWords\n",
    "            i += 1\n",
    "            travleTotalP = self.evaluateTravelP(currentWords)\n",
    "            businessTotalP = self.evaluateBusinessP(currentWords)\n",
    "            if (travleTotalP >= businessTotalP) :\n",
    "                travelCount += 1\n",
    "            else:\n",
    "                businessCount += 1\n",
    "        return [travelCount, businessCount]\n",
    "    \n",
    "    def classify3EvaluateDatas(self, data, dataType) :\n",
    "        travelCount = 0\n",
    "        businessCount = 0\n",
    "        styleCount = 0\n",
    "        for row in data:\n",
    "            \n",
    "            currentWords = row[2]\n",
    "            travleTotalP = self.evaluateTravelP(currentWords)\n",
    "            businessTotalP = self.evaluateBusinessP(currentWords)\n",
    "            styleTotalP = self.evaluateStyleP(currentWords)\n",
    "            if (max(travleTotalP, businessTotalP, styleTotalP) == travleTotalP) :\n",
    "                travelCount += 1\n",
    "            elif (max(travleTotalP, businessTotalP, styleTotalP) == businessTotalP):\n",
    "                businessCount += 1\n",
    "            else: \n",
    "                styleCount += 1\n",
    "        return [travelCount, businessCount, styleCount]      \n",
    "            \n",
    "    \n",
    "    def classify2(self) :\n",
    "        travelPredics = self.classify2EvaluateDatas(self.travelEvaluateData, \"travel\") \n",
    "        businessPredicts = self.classify2EvaluateDatas(self.businessEvaluateData, \"business\")\n",
    "        \n",
    "        travelRecall = \"{:.3f}\".format(travelPredics[0] / (travelPredics[0] + travelPredics[1]) * 100)\n",
    "        travelPrecision = \"{:.3f}\".format(travelPredics[0] / (travelPredics[0] + businessPredicts[0]) * 100)\n",
    "        \n",
    "        businessRecall = \"{:.3f}\".format(businessPredicts[1] / (businessPredicts[0] + businessPredicts[1]) * 100)\n",
    "        businessPrecision = \"{:.3f}\".format(businessPredicts[1] / (travelPredics[1] + businessPredicts[1]) * 100)\n",
    "        \n",
    "        accuracy = \"{:.3f}\".format((travelPredics[0] + businessPredicts[1]) / (travelPredics[0] + travelPredics[1] + businessPredicts[0] + businessPredicts[1]) * 100)\n",
    "        \n",
    "        df2 = pd.DataFrame (columns = ['phase1', 'travel', 'business'])\n",
    "        df2['phase1'] = ['recall', 'precision', 'accuracy']\n",
    "        df2['travel'] = [travelRecall, travelPrecision, accuracy]\n",
    "        df2['business'] = [businessRecall, businessPrecision, accuracy]\n",
    "        return df2\n",
    "        \n",
    "        \n",
    "    def classify3(self) :\n",
    "        travelPredics = self.classify3EvaluateDatas(self.travelEvaluateData, \"travel\") \n",
    "        businessPredicts = self.classify3EvaluateDatas(self.businessEvaluateData, \"business\")\n",
    "        stylePredict = self.classify3EvaluateDatas(self.styleEvaluateData, \"style\")\n",
    "        \n",
    "        travelRecall = \"{:.3f}\".format(travelPredics[0] / (travelPredics[0] + travelPredics[1] + travelPredics[2]) * 100)\n",
    "        travelPrecision = \"{:.3f}\".format(travelPredics[0] / (travelPredics[0] + businessPredicts[0] + stylePredict[0]) * 100)\n",
    "        \n",
    "        businessRecall = \"{:.3f}\".format(businessPredicts[1] / (businessPredicts[0] + businessPredicts[1] + businessPredicts[2]) * 100)\n",
    "        businessPrecision = \"{:.3f}\".format(businessPredicts[1] / (travelPredics[1] + businessPredicts[1] + stylePredict[1]) * 100)\n",
    "        \n",
    "        styleRecall = \"{:.3f}\".format(stylePredict[2] / (stylePredict[0] + stylePredict[1] + stylePredict[2]) * 100)\n",
    "        stylePrecision = \"{:.3f}\".format(stylePredict[2] / (travelPredics[2] + businessPredicts[2] + stylePredict[2]) * 100)\n",
    "        \n",
    "        accuracy = \"{:.3f}\".format((travelPredics[0] + businessPredicts[1] + stylePredict[2]) / (travelPredics[0] + travelPredics[1] + travelPredics[2] + businessPredicts[0] + businessPredicts[1] + businessPredicts[2] + stylePredict[0] + stylePredict[1] + stylePredict[2]) * 100)\n",
    "        \n",
    "        df2 = pd.DataFrame (columns = ['phase1', 'travel', 'business', 'style & beauty'])\n",
    "        df2['phase1'] = ['recall', 'precision', 'accuracy']\n",
    "        df2['travel'] = [travelRecall, travelPrecision, accuracy]\n",
    "        df2['business'] = [businessRecall, businessPrecision, accuracy]\n",
    "        df2['style & beauty'] = [styleRecall, stylePrecision, accuracy]\n",
    "        \n",
    "        \n",
    "        dfConfusion = pd.DataFrame (columns = ['actual / prediction', 'travel', 'business', 'style & beauty'])\n",
    "        dfConfusion['actual / prediction'] = ['travel', 'beauty', 'style & beauty']\n",
    "        dfConfusion['travel'] = [travelPredics[0], travelPredics[1], travelPredics[2]]\n",
    "        dfConfusion['business'] = [businessPredicts[0], businessPredicts[1], businessPredicts[2]]\n",
    "        dfConfusion['style & beauty'] = [stylePredict[0], stylePredict[1], stylePredict[2]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return [df2, dfConfusion]\n",
    "        \n",
    "        \n",
    "    def evaluateTestFile(self) :\n",
    "        col_list = [\"index\", \"headline\", \"short_description\"]\n",
    "        df = pd.read_csv(testFile, usecols=col_list)\n",
    "        indexes = []\n",
    "        results = []\n",
    "        for index, dfRow in df.iterrows() : \n",
    "            headWordList = []\n",
    "            descWordList = []\n",
    "            if (not (isinstance(dfRow[1], float) and math.isnan(dfRow[1]))) : \n",
    "                headWordList = preprocessData(dfRow[1])\n",
    "            \n",
    "            if (not (isinstance(dfRow[2], float) and math.isnan(dfRow[2]))) : \n",
    "                descWordList = preprocessData(dfRow[2])\n",
    "            \n",
    "            currentWords = headWordList + descWordList\n",
    "            \n",
    "            travleTotalP = self.evaluateTravelP(currentWords)\n",
    "            businessTotalP = self.evaluateBusinessP(currentWords)\n",
    "            styleTotalP = self.evaluateStyleP(currentWords)\n",
    "            indexes.append(dfRow[0])\n",
    "            if (max(travleTotalP, businessTotalP, styleTotalP) == travleTotalP) :\n",
    "                results.append(\"TRAVEL\")\n",
    "            elif (max(travleTotalP, businessTotalP, styleTotalP) == businessTotalP):\n",
    "                results.append(\"BUSINESS\")\n",
    "            else: \n",
    "                results.append(\"STYLE & BEAUTY\")\n",
    "        d = [indexes, results]\n",
    "        export_data = zip_longest(*d, fillvalue = '')\n",
    "        with open('output.csv', 'w', encoding=\"ISO-8859-1\", newline='') as myfile:\n",
    "            wr = csv.writer(myfile)\n",
    "            wr.writerow((\"index\", \"category\"))\n",
    "            wr.writerows(export_data)\n",
    "        myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv reading done.\n",
      "words' probability of travels done.\n",
      "words' probability of buisiness done.\n",
      "words' probability of style & beauty done.\n"
     ]
    }
   ],
   "source": [
    "cl = Classifier(dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase1</th>\n",
       "      <th>travel</th>\n",
       "      <th>business</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recall</td>\n",
       "      <td>95.784</td>\n",
       "      <td>95.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>95.784</td>\n",
       "      <td>95.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>95.784</td>\n",
       "      <td>95.784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase1  travel business\n",
       "0     recall  95.784   95.784\n",
       "1  precision  95.784   95.784\n",
       "2   accuracy  95.784   95.784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.classify2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phase1</th>\n",
       "      <th>travel</th>\n",
       "      <th>business</th>\n",
       "      <th>style &amp; beauty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recall</td>\n",
       "      <td>94.379</td>\n",
       "      <td>94.716</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>95.943</td>\n",
       "      <td>95.848</td>\n",
       "      <td>97.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>96.365</td>\n",
       "      <td>96.365</td>\n",
       "      <td>96.365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phase1  travel business style & beauty\n",
       "0     recall  94.379   94.716        100.000\n",
       "1  precision  95.943   95.848         97.266\n",
       "2   accuracy  96.365   96.365         96.365"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = cl.classify3()\n",
    "dataframes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion matrix:</h2>\n",
    "<p>A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix. The confusion matrix shows the ways in which your classification model is confused when it makes predictions. It gives us insight not only into the errors being made by a classifier but more importantly the types of errors that are being made.\n",
    "</p>\n",
    "<p>\n",
    "every cell in confusion matrix demonstrates that how many of the an specific category (first column) predicted to an specific category (first row).\n",
    "</p>\n",
    "<p>\n",
    "We use confusion matrics to calculate accuracy, recall, and precision too.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual / prediction</th>\n",
       "      <th>travel</th>\n",
       "      <th>business</th>\n",
       "      <th>style &amp; beauty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>travel</td>\n",
       "      <td>1679</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beauty</td>\n",
       "      <td>73</td>\n",
       "      <td>1685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>style &amp; beauty</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual / prediction  travel  business  style & beauty\n",
       "0              travel    1679        71               0\n",
       "1              beauty      73      1685               0\n",
       "2      style & beauty      27        23            1779"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.evaluateTestFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style= \"text-align: center\">Issues (final questions in project script.)</h1>\n",
    "<br>\n",
    "\n",
    "<h2>1: Lemmatization or stemming?</h2>\n",
    "<p>The main difference between lemmatization and stemming is the way they work and therefore the result they each of them returns</p>\n",
    "<p><b>Stemming</b> algorithms work by cutting off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word while <b>lemmatization</b>, on the other hand, takes into consideration the morphological analysis of the words. To do so, it is necessary to have detailed dictionaries which the algorithm can look through to link the form back to its lemma.</p>\n",
    "<p>In our project lemmatization works a bit better with better accuracy.</p>\n",
    "<br>\n",
    "\n",
    "<h2>2: Tf-idf.</h2>\n",
    "<p>TF-IDF (term frequency-inverse document frequency) is a statistical measure that evaluates how relevant a word is to a document in a collection of documents.</p>\n",
    "<p>TF-IDF for a word in a document is calculated by multiplying two different metrics:</p>\n",
    "<p>The term frequency of a word in a document. There are several ways of calculating this frequency, with the simplest being a raw count of instances a word appears in a document. Then, there are ways to adjust the frequency, by length of a document, or by the raw frequency of the most frequent word in a document.\n",
    "\n",
    "The inverse document frequency of the word across a set of documents. This means, how common or rare a word is in the entire document set. The closer it is to 0, the more common a word is. This metric can be calculated by taking the total number of documents, dividing it by the number of documents that contain a word, and calculating the logarithm.</p>\n",
    "<p>\n",
    "To put it in more formal mathematical terms, the TF-IDF score for the word t in the document d from the document set D is calculated as follows:\n",
    "    \n",
    "tf-idf(t,d,D) = tf(t,d).idf(t,D).\n",
    "    \n",
    "If we wanted to use this statistic measurement in naive bayes, we first calculate tf-idf(t,d,D) for all documents and use it as p(t|D) in naive bayes.\n",
    "</p>\n",
    "<br>\n",
    "\n",
    "<h2>3: What was the problem if we only count on precision?</h2>\n",
    "<p>Accuracy and precision are two independant measurements. In fact precision refers to the closeness of two or more measurements to each other. so we can have a good precision while accruracy is not good. for example if we test one example with lots of features so that we can decide to the correct category, precision would be high but it's not guaranteed to work well for other examples so accuracy might be low.</p>\n",
    "<br>\n",
    "\n",
    "<h2>4: What if a word is not appeared in a category?</h2>\n",
    "<p>Because we can't multiply total probability with actual zero, thus we need to assign a very small probability to those words which not appeared previously. As i tested, factor of -6 or -7 of 10 is an acceptable value.</p>\n",
    "\n",
    "    \n",
    "    \n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
